{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17d5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfb9e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2151d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e427ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Tim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348a5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d39a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d72aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32800 entries, 0 to 32799\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      32800 non-null  int64 \n",
      " 1   text    32709 non-null  object\n",
      " 2   label   32800 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 768.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b36eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2009ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ea15e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning in progress...\n"
     ]
    }
   ],
   "source": [
    "print('Data cleaning in progress...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2117a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "train['text_clean'] = train['text'].apply(nltk.word_tokenize)\n",
    "print('Tokenization complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47342dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words removed.\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(nltk.corpus.stopwords.words(\"russian\"))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "print('Stop words removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb068c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Как отключить тариф?</td>\n",
       "      <td>FAQ - тарифы и услуги</td>\n",
       "      <td>[Как, отключить, тариф, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>тариф</td>\n",
       "      <td>мобильная связь - тарифы</td>\n",
       "      <td>[тариф]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>тариф</td>\n",
       "      <td>мобильная связь - тарифы</td>\n",
       "      <td>[тариф]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Здрасте я хотел получить золотую карту</td>\n",
       "      <td>FAQ - тарифы и услуги</td>\n",
       "      <td>[Здрасте, хотел, получить, золотую, карту]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Золотую карту</td>\n",
       "      <td>FAQ - тарифы и услуги</td>\n",
       "      <td>[Золотую, карту]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     text                     label  \\\n",
       "0   0                     Как отключить тариф?     FAQ - тарифы и услуги   \n",
       "1   1                                    тариф  мобильная связь - тарифы   \n",
       "2   2                                    тариф  мобильная связь - тарифы   \n",
       "3   3  Здрасте я хотел получить золотую карту      FAQ - тарифы и услуги   \n",
       "4   4                            Золотую карту     FAQ - тарифы и услуги   \n",
       "\n",
       "                                   text_clean  \n",
       "0                  [Как, отключить, тариф, ?]  \n",
       "1                                     [тариф]  \n",
       "2                                     [тариф]  \n",
       "3  [Здрасте, хотел, получить, золотую, карту]  \n",
       "4                            [Золотую, карту]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de125d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization complete.\n",
      "Data cleaning complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
    "print('Lemmatization complete.\\nData cleaning complete.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bd8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = {'FAQ - тарифы и услуги': 0,\n",
    "            'мобильная связь - тарифы': 1,\n",
    "            'Мобильный интернет': 2,\n",
    "            'FAQ - интернет': 3,\n",
    "            'тарифы - подбор': 4,\n",
    "            'Баланс': 5,\n",
    "            'Мобильные услуги': 6,\n",
    "            'Оплата': 7,\n",
    "            'Личный кабинет': 8,\n",
    "            'SIM-карта и номер': 9,\n",
    "            'Роуминг': 10,\n",
    "            'запрос обратной связи': 11,\n",
    "            'Устройства': 12,\n",
    "            'мобильная связь - зона обслуживания': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eaabd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['label'].map(map_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3426aaf",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd53d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorize(vec, X_train, X_test):    \n",
    "    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    \n",
    "    return X_train_vec, X_test_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8ac3deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text_clean'], train['label'], test_size=0.2, shuffle=True)\n",
    "X_train = X_train.apply(lambda x: ' '.join(x))\n",
    "X_test = X_test.apply(lambda x: ' '.join(x))\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcf0ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fbe2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] },\n",
    "         'Random Forest': { 'n_estimators': [1000], 'min_samples_split': [2] }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb0c91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True, n_jobs=4)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d178b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes : {'alpha': 1, 'fit_prior': False}\n",
      "Accuracy: 0.758 \tPrecision: 0.716 \tRecall: 0.676 \t\tF1: 0.691\n",
      "\n",
      "Random Forest : {'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Accuracy: 0.794 \tPrecision: 0.781 \tRecall: 0.713 \t\tF1: 0.738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13782f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_classifier = GradientBoostingClassifier()\n",
    "param_boost = {'learning_rate': [0.05], 'min_samples_split': [2]}\n",
    "boost_clf_grid = GridSearchCV(boost_classifier, param_grid=param_boost, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1184421c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.05], 'min_samples_split': [2]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_clf_grid.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2daf373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_boost = boost_clf_grid.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b1d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 362  266    1    3    7   13   45    3    0   60    5    0    0    0]\n",
      " [  37 2258    3   13    7   29   34    1    2   10    1    1    2    2]\n",
      " [   1   59  183    7    0    3   12    0    0    1    1    0    1    2]\n",
      " [   1   72    8   85    6    0    6    2    0    3    0    0    0    0]\n",
      " [  27  142    0    6  178    3    5    0    0    2    0    0    0    0]\n",
      " [   5  104    6    3    1  409   24   17    0   15    0    1    0    0]\n",
      " [  27  235    5    1    0   25  455   49    2   34   18    1    0    0]\n",
      " [   0   14    0    0    0   23    2  167    0   16    0    0    1    0]\n",
      " [   1   24    0    0    0    2   15    0   75    3    0    0    0    0]\n",
      " [   3   25    1    0    0    5    7    0    3  487    0    2    0    0]\n",
      " [   3    8    0    0    0    0    4    1    0    2   42    0    0    0]\n",
      " [   0    7    1    0    0    0    2    0    0   10    0   36    0    0]\n",
      " [   0   25    4    0    0    4    1    0    0    3    0    0   59    1]\n",
      " [   0    5   13    0    0    0    1    0    0    0    0    0    1   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.47      0.59       765\n",
      "           1       0.70      0.94      0.80      2400\n",
      "           2       0.81      0.68      0.74       270\n",
      "           3       0.72      0.46      0.56       183\n",
      "           4       0.89      0.49      0.63       363\n",
      "           5       0.79      0.70      0.74       585\n",
      "           6       0.74      0.53      0.62       852\n",
      "           7       0.70      0.75      0.72       223\n",
      "           8       0.91      0.62      0.74       120\n",
      "           9       0.75      0.91      0.83       533\n",
      "          10       0.63      0.70      0.66        60\n",
      "          11       0.88      0.64      0.74        56\n",
      "          12       0.92      0.61      0.73        97\n",
      "          13       0.75      0.43      0.55        35\n",
      "\n",
      "    accuracy                           0.74      6542\n",
      "   macro avg       0.78      0.64      0.69      6542\n",
      "weighted avg       0.75      0.74      0.72      6542\n",
      "\n",
      "0.7354020177315805\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predict_boost))\n",
    "print(classification_report(y_test,predict_boost))\n",
    "print(accuracy_score(y_test, predict_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0ac0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {'n_estimators': [1000],\n",
    "    'min_samples_split': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d37bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5769be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf_rf = GridSearchCV(classifier, param_grid=param_rf, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cdc990a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'min_samples_split': [2], 'n_estimators': [1000]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf_rf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "582114f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2, 'n_estimators': 1000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa8c98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_clf_rf = grid_clf_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "470bfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_grid = best_grid_clf_rf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "746c1b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 434  180    2    3   13   13   29    3    1   42    3    0    0    0]\n",
      " [  46 2207    6    9   29   23   31    2    2    7    0    6    4    1]\n",
      " [   1   32  220    6    0    2    6    0    0    4    0    0    4    1]\n",
      " [   3   34    8  107    9    7    3    0    2    1    0    0    0    0]\n",
      " [  21  117    1    5  230    1    5    0    0    0    0    0    0    0]\n",
      " [   5   51    5    5    0  508   17   12    4    6    2    0    4    0]\n",
      " [  24  104    6    3    3   22  610   12    5   13   11    1    1    0]\n",
      " [   1    8    0    0    0   19   18  180    1    4    1    0    1    0]\n",
      " [   3   11    0    0    0    5   17    0   87    4    0    0    1    0]\n",
      " [   8   13    0    1    0    5    9    2    1  502    0   15    0    0]\n",
      " [   4    5    1    1    0    2   10    2    0    2   52    0    1    0]\n",
      " [   0    9    0    0    0    2    2    0    0    0    0   49    0    0]\n",
      " [   2    8    6    0    0    0    5    0    1    7    0    1   61    0]\n",
      " [   0    4   12    0    0    1    1    0    1    0    0    0    0   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68       723\n",
      "           1       0.79      0.93      0.86      2373\n",
      "           2       0.82      0.80      0.81       276\n",
      "           3       0.76      0.61      0.68       174\n",
      "           4       0.81      0.61      0.69       380\n",
      "           5       0.83      0.82      0.83       619\n",
      "           6       0.80      0.75      0.77       815\n",
      "           7       0.85      0.77      0.81       233\n",
      "           8       0.83      0.68      0.75       128\n",
      "           9       0.85      0.90      0.87       556\n",
      "          10       0.75      0.65      0.70        80\n",
      "          11       0.68      0.79      0.73        62\n",
      "          12       0.79      0.67      0.73        91\n",
      "          13       0.87      0.41      0.55        32\n",
      "\n",
      "    accuracy                           0.80      6542\n",
      "   macro avg       0.80      0.71      0.75      6542\n",
      "weighted avg       0.80      0.80      0.80      6542\n",
      "\n",
      "0.8040354631611129\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predict_grid))\n",
    "print(classification_report(y_test,predict_grid))\n",
    "print(accuracy_score(y_test, predict_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe08b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
